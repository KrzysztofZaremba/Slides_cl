---
title: 'Class 3b: Review of concepts in Probability and Statistics'
author: "Business Forecasting"
output:
  xaringan::moon_reader:
    self_contained: true
    css: xaringan-themer.css
    lib_dir: libs
    nature:
      highlightStyle: github
      countIncrementalSlides: true
      
---   
<style type="text/css">
.remark-slide-content {
    font-size: 20px;
}

</style>

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, dpi = 300)
library(shiny)
library(ggplot2)
library(forecast)
library(plotly)
library(dplyr)
library(igraph)
library(reshape)
library(spData)
library(leaflet)
library(readr)
library(gridExtra)
library(hrbrthemes)
library(viridis)
library(gapminder)
library(knitr)
library(kableExtra)
library(DT)
load("sample_listing.Rda")
```

```{r xaringan-themer, include=FALSE, warning=FALSE}
library(xaringanthemer)
style_mono_accent(base_color = "#43418A",
colors = c(
  red = "#f34213",
  purple = "#3e2f5b",
  orange = "#ff8811",
  green = "#136f63",
  blue = "#1E90FF",
  white = "#FFFFFF"
))
```


---
layout: false
class: inverse, middle

# Confidence Intervals

---
### Confidence Intervals

- We calculated the mean price in our sample

- How confident are we that our estimate is close to the parameter's value?

- Confidence intervals measure uncertainty around the estimate

---
### Confidence Intervals

- Mean price was 1245.43

--
- Is it reasonable to think true average price in population is 1100? What about 2000?

--
- Suppose that we calculated the confidence interval to be:
$$\{1086.64, 1404.22\}$$

--
    - Where are these numbers coming from?

--

  1. The sampling distribution of the sample mean tells us how likely we are to get a point estimate which is far away from the true mean

--

  2. The confidence interval uses this property of the sampling distribution to tell us where the true mean might be

--

 - Let's go through these statements 1-by-1
  
---
### Sampling distribution

**Q: How likely is it that a sample mean is far away from the true mean?**

- Consider a hypothetical sampling distribution of a sample mean
  - Reminder: $\bar{x} \sim \mathcal{N}(\mu, \frac{\sigma}{\sqrt{n}})$
  
--
- If we draw samples repeatedly, 95% of their means will be within the shaded area 
- Why 1.96?

```{r, warning=FALSE, fig.height=3.3, out.width='100%'}
# plot the standard normal density on the interval [-4,4]
curve(dnorm(x),
      xlim = c(-3, 3),
      main = "Sampling Distribution of Sample mean",
      yaxs = "i",
      xlab = "z",
      ylab = "",
      lwd = 2,
      axes = "F")


# add x-axis
axis(1, 
     at = c(-1.96,  0,  1.96), 
     padj = 0.75,
     labels = c(expression(mu - 1.96*frac(sigma,sqrt(n))),
                expression(mu),
                expression(mu + 1.96*frac(sigma,sqrt(n)))))

# add a vertical line at the mean (mu)

transparent_color <- rgb(70, 130, 180, alpha = 50, maxColorValue = 255)

# shade the middle 95% region
polygon(x = c(-1.96, seq(-1.96, 1.96, 0.01), 1.96),
        y = c(0, dnorm(seq(-1.96, 1.96, 0.01)), 0),
        col = transparent_color )

abline(v = 0, col = "red", lwd = 2)

# add the "95%" label
text(0, 0.2, "95%", col = "black", cex = 1.5)

```

---

### Yet another way to see it


\begin{align*}
0.95&= P(-1.96<Z<1.96) \\
&= P(-z_{\frac{\alpha}{2}}<Z<z_{\frac{\alpha}{2}}) \\
&= P\left(-z_{\frac{\alpha}{2}}<\frac{\bar{X}-\mu}{\sigma/\sqrt  n}<z_{\frac{\alpha}{2}}\right) \\
&= P\left(-z_{\frac{\alpha}{2}}\cdot\sigma/ \sqrt n<\bar{X}-\mu<z_{\frac{\alpha}{2}}\cdot\sigma/\sqrt  n\right) \\
&= P\left(\mu-z_{\frac{\alpha}{2}}\cdot\sigma/\sqrt  n< \bar{X} <\mu+z_{\frac{\alpha}{2}}\cdot\sigma/\sqrt  n\right) \\
\end{align*}


  - Theoretically, CLT theorem guarantees that $\frac{\bar{X}-\mu}{\sigma/\sqrt  n}$ is standard normal
  
--
  
  - What happens if you do not know $\sigma$?

--

  - In large sample, $s \rightarrow \sigma$, so $\frac{\bar{X}-\mu}{s/\sqrt  n} \rightarrow N(0,1)$
  - So in large samples, standardized sample mean (with estimated standard deviation) will also have normal distribution
  - You may need a bit higher n to ensure $s \rightarrow \sigma$

---

### Sampling distribution

**Q: How far is the sampled mean from the true mean?**

- Hence 95% of the draws of sample means will be within distance of $1.96\frac{\sigma_X}{\sqrt n}$ to the true parameter
- There is only 5% chance that we have draw sample weird enough that $\bar{X}$ is further from $\mu_X$ by more than $1.96\frac{\sigma_X}{ \sqrt n}$
- Confidence interval of $\bar{X}$ will cover $\mu_X$ as long as $|\mu_X-\bar{X}|<1.96\frac{\sigma_X}{\sqrt  n}$

```{r, warning=FALSE, fig.height=3, out.width='100%'}
curve(dnorm(x),
      xlim = c(-4, 4),
      main = "Sampling Distribution of Sample Mean",
      yaxs = "i",
      xlab = "z",
      ylab = "",
      lwd = 2,
      axes = "F")

# add x-axis
axis(1, 
     at = c(-1.96, 0, 1.96), 
     padj = 0.75,
     labels = c(expression(mu - 1.96*frac(sigma, sqrt(n))),
                expression(mu),
                expression(mu + 1.96*frac(sigma, sqrt(n)))))

# shade the tails for the 2.5% regions
transparent_color <- rgb(70, 130, 180, alpha = 50, maxColorValue = 255)
polygon(x = c(-1.96, seq(-1.96, 1.96, 0.01), 1.96),
        y = c(0, dnorm(seq(-1.96, 1.96, 0.01)), 0),
        col = transparent_color)

# add vertical line at the mean (mu)
abline(v = 0, col = "red", lwd = 2)

# calculate the position halfway between the mean and the 95% confidence interval
position <- (0 + 1.96) / 2

# add a point for x̄ (sample mean)
whisker_left <- -1.96 * 1 / sqrt(1)  # Adjust '1' if necessary
whisker_right <- 1.96 * 1 / sqrt(1)   # Adjust '1' if necessary

# add a point for x̄ (sample mean)
points(position, 0.15, pch = 16, col = "red", cex = 2)

# add whiskers for confidence bands
segments(position + whisker_left, 0.15, position + whisker_right, 0.15, col = "red", lwd = 2)
segments(position + whisker_left, 0.14, position + whisker_left, 0.16, col = "red", lwd = 2)
segments(position + whisker_right, 0.14, position + whisker_right, 0.16, col = "red", lwd = 2)

text(position + whisker_left + 0.05, .21, expression(bar(x) - 1.96*frac(sigma, sqrt(n))), col = "red", cex = 1)
text(position + whisker_right - 0.05, .21, expression(bar(x) + 1.96*frac(sigma, sqrt(n))), col = "red", cex = 1)
text(position, 0.21, expression(bar(x)), col = "red", cex = 1.2)

```


---
### Sampling distribution

- Suppose we draw many samples from the same distribution
- For each sample we compute the sample mean and we construct the interval
- 95% of them will cover the true population mean!

`r knitr::include_url('https://seeing-theory.brown.edu/frequentist-inference/index.html#section2', height='400px')`

  Source: [Seeing Theory](https://seeing-theory.brown.edu/frequentist-inference/index.html#section2)


---

### Calculation Procedure

Use this procedure if $n>40$
1. Take an IID sample

--
2. Calculate mean $\bar{x}$ and standard deviation $s$ in your sample
  - Standard Error is standard deviation of the estimator $\small SE=\frac{s}{\sqrt n}$

--
3. Pick confidence level (usually 90,95,99%)
  - We typically denote the confidence level $1-\alpha$
  - $\alpha$ is probability of making a Type 1 error (more about it later)
  - .blue[Example]: if confidence level is 95%, $\small \alpha=0.05$
  
--

4. Find the corresponding critical values $\small z_{\frac{\alpha}{2}}$
  - Critical values are such that $\small P(-z_{\frac{\alpha}{2}}<Z<z_{\frac{\alpha}{2}})=1-\alpha$
  - .blue[Example]: if confidence level is 95%, $\small z_\frac{\alpha}{2}=z_{0.025}=1.96$
--

5. Construct the confidence interval as:
$$\small \{\bar{x}- z_{\frac{\alpha}{2}}*\underbrace{\frac{s}{\sqrt n}}_{SE}, \bar{x}+ z_{\frac{\alpha}{2}}*\frac{s}{\sqrt n}\}$$


---
### Finding Critical Values

- Suppose confidence interval is 99%. 
- Then $\alpha=0.01$
- We are looking for $z_{\frac{\alpha}{2}}$ such that:
$$P(-z_{\frac{\alpha}{2}}<Z<z_{\frac{\alpha}{2}})=0.99$$
```{r, warning=FALSE, fig.height=3, out.width='100%'}
curve(dnorm(x),
      xlim = c(-4, 4),
      main = "Standard normal",
      yaxs = "i",
      xlab = "z",
      ylab = "",
      lwd = 2,
      axes = "F")

# add x-axis
axis(1, 
     at = c(-2.58, 0, 2.58), 
     padj = 0.75,
     labels = c(expression(-z[0.005]),
                expression(0),
                expression(z[0.005])))

# shade the tails for the 2.5% regions
polygon(x = c(-4, seq(-4, -2.58, 0.01), -2.58),
        y = c(0, dnorm(seq(-4, -2.58, 0.01)), 0),
        col = "steelblue")

polygon(x = c(2.58, seq(2.58, 4, 0.01), 4),
        y = c(0, dnorm(seq(2.58, 4, 0.01)), 0),
        col = "steelblue")

# add vertical line at the mean (mu)
abline(v = 0, col = "red", lwd = 2)

# add the "2.5%" labels on tails
text(-2.9, 0.05, "0.5%", col = "black", cex = 1.5)
text(2.9, 0.05, "0.5%", col = "black", cex = 1.5)
```

--
$$P(Z>z_{0.005})=0.005 \qquad\text{or}\qquad P(Z<z_{0.005})=0.995$$
---

`r knitr::include_url('https://www.mathsisfun.com/data/standard-normal-distribution-table.html', height='480px')`
  Source: [Maths is Fun](https://www.mathsisfun.com/data/standard-normal-distribution-table.html)




---
### Finding Critical Values

$P(Z<z_{\frac{\alpha}{2}})=0.995$ 
$z_{\frac{\alpha}{2}}$, is 99.5% quantile of standard normal $\rightarrow$ $z_{\frac{\alpha}{2}}=2.58$
```{r, warning=FALSE, fig.height=2.5, out.width='100%'}
curve(dnorm(x),
      xlim = c(-4, 4),
      main = "Standard normal",
      yaxs = "i",
      xlab = "z",
      ylab = "",
      lwd = 2,
      axes = "F")

# add x-axis
axis(1, 
     at = c(-2.58, 0, 2.58), 
     padj = 0.75,
     labels = c(expression(-z[0.005]),
                expression(0),
                expression(z[0.005])))

# shade the tails for the 2.5% regions
polygon(x = c(-4, seq(-4, 2.58, 0.01), 2.58),
        y = c(0, dnorm(seq(-4, 2.58, 0.01)), 0),
        col = "steelblue")

# add vertical line at the mean (mu)
abline(v = 0, col = "red", lwd = 2)

# add the "2.5%" labels on tails
text(0, 0.2, "99.5%", col = "black", cex = 1.5)
text(3.5, 0.1, "0.5%", col = "black", cex = 1.5)
```

---
### Constructing CI: example
Let's calculate 90% CI for average price of listings with cleanliness score > 4.5

1. Take an IID sample 
  - $n=100$ $\checkmark$

--
2. Calculate mean $\bar{x}$ and standard deviation $s$
  - $\bar{x}=$ `r format(round(mean(Sample_list[Sample_list$clean==TRUE | Sample_list$clean=="Clean",]$price),2), scientific=FALSE)` and $s=$ `r format(round(sd(Sample_list[Sample_list$clean==TRUE | Sample_list$clean=="Clean",]$price),2), scientific=FALSE)`

--
3. Pick confidence level
  - We pick 90%, so $\alpha=0.1$
  
--

4. Find the corresponding critical values $z_{\frac{\alpha}{2}}$
  - Find $z_\frac{\alpha}{2}$ such that $P(Z>z_{\frac{\alpha}{2}})=0.05$ (or $P(Z<z_{\frac{\alpha}{2}})=0.95$)
  - $z_{0.05}=1.65$
--

5. Construct the confidence interval as:
$$\small \{\bar{x}- z_{\frac{\alpha}{2}}*\frac{s}{\sqrt n}, \bar{x}+ z_{\frac{\alpha}{2}}*\frac{s}{\sqrt n}\}$$
$$\small \{1245.43- 1.65\frac{961.9}{\sqrt{100}}, 1245.43+ 1.65\frac{961.9}{\sqrt{100}}\}$$

---
### Interpreting confidence intervals

$$\small CI_{90}=\{1086.64, 1404.22\}$$

How do we interpret a 90% confidence interval we computed?

- **Correct Interpretation**
  - We are 90% confident that the interval captures the true mean
  - We are 90% confident that the true mean price of listings with cleanliness score > 4.5 is between 1086.64 and 1404.22
  
--

- **Incorrect**
  - With 90% probability the true mean is between 1086.64 and 1404.22
      - Computed interval is not-random and true mean is not random, so can't make probabilistic statements.
      - Interval is a function of random variables only **before** we draw a sample and make any computation.
      - After we have a sample, nothing is random. The true mean is either between 1086.64 and 1404.22 or not.

---

<center>
<img src=airbnb_True.png width="800">
</center>



---

### Shape of confidence intervals

Confidence intervals $\small \{\bar{x}- z_{\frac{\alpha}{2}}*\frac{s}{\sqrt n}, \bar{x}+ z_{\frac{\alpha}{2}}*\frac{s}{\sqrt n}\}$ are wider when: 
- Confidence level is higher (99% is wider than 90%)
- When $n$ is small
- When $\sigma$ is large

`r knitr::include_url('https://seeing-theory.brown.edu/frequentist-inference/index.html#section2', height='420px')`



---
### Practice

In learnr:

0. Set seed to your student id.
1. Take a sample of 100 observations from the data
2. Calculate the mean and standard deviation of the sample
3. Find critical value
4. Compute confidence interval

---

### What critical values?

When should we use critical values from Normal Distribution?


1. Original distribution (of $X$) is not normal:

  - If $n>30$ — use critical values from normal distribution (use $n>40$ if $\sigma$ unknown, to give $s$ enough data to approximate $\sigma$)

  - If $n<30$ — normal approximation is unreliable; you need specialized methods (e.g., bootstrap)


--
2. Original distribution (of $X$) is normal: 

  - If you know $\sigma$, you can use critical values from normal ( $n$ doesn't matter)
      - If $X$ is normal, then use $\sigma$ instead of $s$ and $\frac{\bar{X}-\mu}{\frac{\sigma}{\sqrt n}} \sim N(0,1)$ 

  - If you don't know $\sigma$ but $n>40$, you can use critical values from normal
      - CLT kicks in

  - If you don't know $\sigma$ and $n<40$, you use critical values from .blue[student's t].
      - $\frac{\bar{X}-\mu}{\frac{s}{\sqrt n}}$ is not normal. $s$ is not a good approx. of $\sigma$ when $n$ is low
    


---
### What's  Student's t?

If $X_1$, $X_2$, . . . , $X_n$ are i.i.d. from $N(µ, σ)$, then
$$T =\frac{\bar{X} − µ}{s/\sqrt n}$$
Where $s$ is sample standard deviation. 

T has a student's t distribution with n−1 degrees of freedom
$$T \sim t_{n-1}$$


---
### What's  Student's t?

- Bell shaped and symmetric around 0 
- More spread out - heavier tails, more uncertainty (because we don't know standard deviation)
- Shape determined by the degrees of freedom. 
  - As n increases (and hence degrees of freedom), it tends to standard normal (as it should by CLT!)
  - Less uncertainty because we are better at estimating standard deviation

```{r abc, warning=FALSE, fig.height=2.5, out.width='100%'}
# Parameters
df_values <- c(3, 10, 30)  # Different degrees of freedom
x_vals <- seq(-4, 4, length.out = 400)
normal_density <- dnorm(x_vals)

# Create a data frame for ggplot
df <- data.frame(x = rep(x_vals, length(df_values) + 1),
                 y = c(sapply(df_values, function(df) dt(x_vals, df)), normal_density),
                 distribution = rep(c(paste("t-distribution (df =", df_values, ")"), "Normal distribution"), each = length(x_vals)))

# Create ggplot object
gg_plot <- ggplot(df, aes(x = x, y = y, color = distribution)) +
  geom_line() +
  labs(x = "x",
       y = "Density") +
  theme_minimal()

# Convert to plotly object for interactivity
 ggplotly(gg_plot,
        width = 800,   # Adjust the width according to your preference
        height = 300)

```


---
### Student's t critical values

Finding critical values for student's t distribution:

1. Determine what is the right number of degrees of freedom ( $n-1$ )!
2. Determine what's your confidence level and your $(1-\alpha)$
  - From this figure out $\alpha/2$
  
3. Find the percentile such that 

$$P(T>t_{\frac{\alpha}{2},\underbrace{n-1}_{d.f.}})=\frac{\alpha}{2} \qquad\text{or}\qquad P(T<t_{\frac{\alpha}{2},n-1})=1-\frac{\alpha}{2}$$

```{r, warning=FALSE, fig.height=2.5, out.width='100%'}
# Parameters
n <- 10  # Sample size
df <- n - 1  # Degrees of freedom for t-distribution
mu <- 0    # Mean of the distribution
sigma <- 1  # Standard deviation of the distribution

# Create a sequence of x values
x_vals <- seq(-4, 4, by = 0.01)

# Calculate the density values for the t-distribution
t_density <- dt(x_vals, df)

# Plotting
plot(x_vals, t_density, type = "l", xlim = c(-4, 4), ylim = c(0, 0.4),
     main = "Student's t with 9df",
     yaxs = "i", xlab = "t", ylab = "", lwd = 2, axes = "F")

# Add x-axis
axis(1, at = c(-2.26, 0, 2.26), padj = 0.75,
     labels = c(expression(-t[frac(alpha,2)*","~df]),
                0,
                expression(t[frac(alpha,2)*","~df])))

# Add a vertical line at the mean (mu)
abline(v = 0, col = "red", lwd = 2)

# Shade the middle 95% region
transparent_color <- rgb(70, 130, 180, alpha = 50, maxColorValue = 255)
polygon(x = c(-2.26, seq(-2.26, 2.26, 0.01), 2.26),
        y = c(0, dt(seq(-2.26, 2.26, 0.01), df), 0),
        col = transparent_color)

# Add the "95%" label
text(0, 0.2, "95%", col = "black", cex = 1.5)

text(3, 0.2, "2.5%", col = "black", cex = 1.5)

```


---
### Example

- Practice in learnr finding critical values using the code:

```r
qt(quantile, degrees_of_freedom)
#ex
qt(0.975, 9)
```

---
- $n=10 \rightarrow df=9$
- Confidence level is 95% $\rightarrow1-\alpha=0.95$ and $\frac{\alpha}{2}=0.025$
- What's $t_{0.025,9}$ such that $P(T<t_{0.025,9})=0.975$

```{r, warning=FALSE, fig.height=3.5, out.width='100%'}
# Parameters
n <- 10  # Sample size
df <- n - 1  # Degrees of freedom for t-distribution
mu <- 0    # Mean of the distribution
sigma <- 1  # Standard deviation of the distribution

# Create a sequence of x values
x_vals <- seq(-4, 4, by = 0.01)

# Calculate the density values for the t-distribution
t_density <- dt(x_vals, df)

# Plotting
plot(x_vals, t_density, type = "l", xlim = c(-4, 4), ylim = c(0, 0.4),
     main = "Student's t with 9df",
     yaxs = "i", xlab = "t", ylab = "", lwd = 2, axes = "F")

# Add x-axis
axis(1, at = c(-2.26, 0, 2.26), padj = 0.75,
     labels = c(expression(-2.26),
                0,
                expression(2.26)))

# Add a vertical line at the mean (mu)
abline(v = 0, col = "red", lwd = 2)

# Shade the middle 95% region
transparent_color <- rgb(70, 130, 180, alpha = 50, maxColorValue = 255)
polygon(x = c(-2.26, seq(-2.26, 2.26, 0.01), 2.26),
        y = c(0, dt(seq(-2.26, 2.26, 0.01), df), 0),
        col = transparent_color)

# Add the "95%" label
text(0, 0.2, "95%", col = "black", cex = 1.5)

text(3, 0.05, "2.5%", col = "black", cex = 1.5)

```
- Once we have critical value, we construct the CI as before:

$$\small \{\bar{x}- t_{\frac{\alpha}{2},n-1}*\frac{s}{\sqrt n}, \bar{x}+ t_{\frac{\alpha}{2},n-1}*\frac{s}{\sqrt n}\}$$



---
### Practice in learnr:

Your company implemented free shipping for a random group of customers. They want to know whether it increased spending.
Here is your data:

$157.80, $192.45, $210.20, $175.60, $198.30, $180.90, $205.75, $185.20, $177.40, $195.60 


a) Calculate 90% confidence interval. What assumptions you need?

--

b) Average spending without free shipping is $182, can say anything about whether free shipping increased spending?


---
### Confidence Intervals for Variance

- Sometimes we care about how spread out a process is, not just its mean
- Example: in manufacturing, a machine that produces bolts with high variance in diameter is unreliable, even if the average diameter is correct

--

- Suppose $X_1, X_2, ...X_n$ come from a normal distribution
- The sampling distribution of the sample variance  $S^2=\frac{\sum_i(X_i-\bar{X})^2}{n-1}$ is:

$$\small \frac{(n-1)S^2}{\sigma^2}\sim\chi^2_{n-1}$$
--
- We will use the fact that:  
$$\small P(\chi^2_{0.025,n-1}<\frac{(n-1)S^2}{\sigma^2}<\chi^2_{0.975,n-1})=0.95$$

```{r, warning=FALSE, fig.height=3, out.width='100%'}
df <- 9  # Degrees of freedom for chi-square distribution

# Create a sequence of x values
x_vals <- seq(0, 25, by =0.01)

# Calculate the density values for the chi-square distribution
chi_density <- dchisq(x_vals, df)

# Plotting
plot(x_vals, chi_density, type = "l", xlim = c(0, 25), ylim = c(0, 0.2),
     main = "Chi-Square with 9df",
     yaxs = "i", xlab = "x", ylab = "", lwd = 2, axes = FALSE)

# Add x-axis


# Add a vertical line at the mean (mu)
abline(v = 9, col = "red", lwd = 2)

# Calculate quantiles for shading
q_lower <- qchisq(0.025, df)
q_upper <- qchisq(1 - 0.025, df)

# Shade the middle 95% region
polygon(x = c(0, seq(0, q_lower, by =0.01), q_lower, q_upper, seq(q_upper, 25, by=0.01), 25),
        y = c(0, dchisq(seq(0, q_lower, by =0.01), df), 0, 0, dchisq(seq(q_upper, 25, by =0.01), df), 0),
        col = transparent_color)

# Add the "95%" labels
text(q_lower -0.5, 0.05, "2.5%", col = "black", cex = 1.5)
text(q_upper +0.5, 0.05, "2.5%", col = "black", cex = 1.5)

axis(1, at = c(0, q_lower, 9,q_upper, 25), padj = 0.75,
     labels = c(0,expression(chi[0.025]), 9,expression(chi[0.975]), 25))

```

---
### Confidence Intervals for Variance

How we use it to construct the confidence interval?

\begin{align*}
0.95&= P\left(\chi^2_{0.025,n-1}<\frac{(n-1)S^2}{\sigma^2}<\chi^2_{0.975,n-1}\right) \\
&= P\left(\frac{1}{\chi^2_{0.975,n-1}} < \frac{\sigma^2}{(n-1)S^2} < \frac{1}{\chi^2_{0.025,n-1}}\right) \\
&= P\left(\frac{(n-1)S^2}{\chi^2_{0.975,n-1}} < \sigma^2 < \frac{(n-1)S^2}{\chi^2_{0.025,n-1}}\right)
\end{align*}

--
So more generally, the confidence interval for the sample variance is 

$$CI_{1-\alpha}=\left\{\frac{(n-1)S^2}{\chi^2_{1-\frac{\alpha}{2},n-1}}, \frac{(n-1)S^2}{\chi^2_{\frac{\alpha}{2},n-1}}\right\}$$
- Where $\chi^2_{1-\frac{\alpha}{2},n-1}$ and $\chi^2_{\frac{\alpha}{2},n-1}$ are quantiles of the $\chi^2_{n-1}$ distribution, such that $P(X<\chi^2_{1-\frac{\alpha}{2},n-1})=1-\frac{\alpha}{2}$ and $P(X<\chi^2_{\frac{\alpha}{2},n-1})=\frac{\alpha}{2}$
- You can find them in R using: 

```r
qchisq(alpha, df)
```

---
### Practice in learnr

Suppose you produce sausages. As quality control, you measure the level of fat in your sausages. You take a random sample of 12 sausages and you find the sample variance of 20 $\text{grams}^2$. Find 99% confidence interval for the population variance. What assumptions do you need?

---
