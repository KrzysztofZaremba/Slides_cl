---
title: "LearnR Tutorial: Estimators and Confidence Intervals"
author: "Business Forecasting"
output: learnr::tutorial
runtime: shiny_prerendered
---

## Population

We start with a simulated population drawn from an Exponential(2) distribution. This is intentionally **non-normal** ‚Äî it is right-skewed and bounded below by 0. This lets us see how estimators behave when the population is far from a bell curve.

```{r setup, include=FALSE}
library(learnr)
library(shiny)
library(ggplot2)
library(dplyr)

set.seed(123)

# ---- Non-normal population: Exponential ----
POP_SIZE <- 5e5
EXP_RATE <- 2
population <- rexp(POP_SIZE, rate = EXP_RATE)

# Population benchmarks
pop_sd     <- sd(population)
pop_iqr    <- IQR(population)
pop_q99    <- as.numeric(quantile(population, 0.99))
pop_median <- median(population)
pop_mean   <- 1 / EXP_RATE   # true mu = E[X] for Exp(rate)

# ---- Ride-hailing population for CI exercise ----
set.seed(2025)
N <- 20000
base <- rnorm(N, mean = 120, sd = 18)
surge <- rlnorm(N, meanlog = log(1.10), sdlog = 0.25)
noise <- rnorm(N, mean = 0, sd = 8)
orders_pop <- pmax(35, base * surge + noise)
true_mu <- mean(orders_pop)
true_sd <- sd(orders_pop)

# ---- Free shipping experiment data ----
spend_free <- c(157.80, 192.45, 210.20, 175.60, 198.30,
                180.90, 205.75, 185.20, 177.40, 195.60)

```


```{r pop_plot, context="render"}
plotOutput("pop_hist", height = 300)
```
```{r pop_plot_server, context="server"}
output$pop_hist <- renderPlot({
  df <- data.frame(x = population)
  xmax <- pop_q99
  ggplot(df, aes(x = x)) +
    geom_histogram(aes(y = after_stat(density)), bins = 120, color = "white", fill = "grey70") +
    coord_cartesian(xlim = c(0, xmax)) +
    labs(title = paste0("Population: Exponential(rate=", EXP_RATE, "), true mean = ", pop_mean),
         x = "Value", y = "Density") +
    theme_minimal()
})
```

---


## Panel A ‚Äî Standard Deviation

Explore the sampling distribution of the sample standard deviation. The dashed line shows the true population SD.

**Questions to consider:** What happens as you increase n? Is the sample SD an unbiased estimator of the population SD?

```{r ui_sd, context="render"}
fluidPage(
  numericInput("n_sd", "Sample size (n):", value = 30, min = 2, step = 1),
  numericInput("B_sd", "Number of samples (B):", value = 1000, min = 50, step = 50),
  actionButton("go_sd", "Simulate SD", class = "btn-primary"),
  plotOutput("sd_dist", height = 280)
)
```

```{r server_sd, context="server"}
observeEvent(input$go_sd, {
  n <- input$n_sd; B <- input$B_sd
  sds <- replicate(B, sd(sample(population, size = n, replace = TRUE)))
  output$sd_dist <- renderPlot({
    ggplot(data.frame(stat = sds), aes(x = stat)) +
      geom_histogram(bins = 50, fill = "steelblue", color = "white") +
      geom_vline(xintercept = pop_sd, linetype = "dashed") +
      labs(title = paste0("Sampling Distribution of SD (n=", n, ", B=", B, ")"),
           x = "Sample SD", y = "Count") +
      theme_minimal() + xlim(0, max(sds) * 1.1)
  })
})
```

---

## Panel B ‚Äî Interquartile Range (IQR)

The IQR is another measure of spread. Explore its sampling distribution and compare it to the SD panel.

**Questions to consider:** Is the IQR more or less variable than the SD across samples? Which converges faster?

```{r ui_iqr, context="render"}
fluidPage(
  numericInput("n_iqr", "Sample size (n):", value = 30, min = 2, step = 1),
  numericInput("B_iqr", "Number of samples (B):", value = 1000, min = 50, step = 50),
  actionButton("go_iqr", "Simulate IQR", class = "btn-primary"),
  plotOutput("iqr_dist", height = 280)
)
```
```{r server_iqr, context="server"}
observeEvent(input$go_iqr, {
  n <- input$n_iqr; B <- input$B_iqr
  iqrs <- replicate(B, IQR(sample(population, size = n, replace = TRUE)))
  output$iqr_dist <- renderPlot({
    ggplot(data.frame(stat = iqrs), aes(x = stat)) +
      geom_histogram(bins = 50, fill = "seagreen", color = "white") +
      geom_vline(xintercept = pop_iqr, linetype = "dashed") +
      labs(title = paste0("Sampling Distribution of IQR (n=", n, ", B=", B, ")"),
           x = "Sample IQR", y = "Count") +
      theme_minimal() + xlim(0, max(iqrs) * 1.1)
  })
})
```

---

## Panel C ‚Äî 99th Percentile

Now explore the sampling distribution of the **sample 99th percentile**. The dashed line shows the true population 99th percentile.

**Questions to consider:** Is this estimator biased? How does increasing n affect the distribution?

```{r ui_max, context="render"}
fluidPage(
  numericInput("n_max", "Sample size (n):", value = 30, min = 2, step = 1),
  numericInput("B_max", "Number of samples (B):", value = 1000, min = 50, step = 50),
  actionButton("go_max", "Simulate 99th Percentile", class = "btn-primary"),
  plotOutput("max_dist", height = 280)
)
```

```{r server_max, context="server"}
observeEvent(input$go_max, {
  n <- input$n_max; B <- input$B_max
  pct99s <- replicate(B, as.numeric(quantile(sample(population, size = n, replace = TRUE), 0.99)))
  output$max_dist <- renderPlot({
    ggplot(data.frame(stat = pct99s), aes(x = stat)) +
      geom_histogram(bins = 50, fill = "tomato", color = "white") +
      geom_vline(xintercept = pop_q99, linetype = "dashed") +
      labs(title = paste0("Sampling Distribution of 99th Percentile (n=", n, ", B=", B, ")"),
           x = "Sample 99th Percentile", y = "Count") +
      theme_minimal() + xlim(0, max(pct99s) * 1.1)
  })
})
```

---

## Example 1: Estimator \( \hat{\theta}_1 = X_i \) (a single observation)
- \( E(\hat{\theta}_1) = E(X_i) = \mu \) ‚Üí **unbiased**.
- But is it a good estimator? Run the simulation and look at the variance!

```{r ui_theta2, context="render"}
fluidPage(
  numericInput("B_t2", "Number of repetitions (B):", value = 3000, min = 100, step = 100),
  actionButton("go_t2", "Simulate Œ∏‚ÇÅ = X·µ¢", class = "btn-primary"),
  plotOutput("theta2_plot", height = 300),
  verbatimTextOutput("theta2_stats")
)
```

```{r server_theta2, context="server"}
observeEvent(input$go_t2, {
  B <- input$B_t2
  theta2 <- rexp(B, rate = EXP_RATE)
  emp_mean <- mean(theta2)
  emp_bias <- emp_mean - pop_mean
  E_theta2 <- pop_mean

  output$theta2_plot <- renderPlot({
    ggplot(data.frame(theta = theta2), aes(x = theta)) +
      geom_histogram(bins = 80, fill = "mediumpurple", color = "white") +
      geom_vline(xintercept = pop_mean, linetype = "dashed", linewidth = 1) +
      geom_vline(xintercept = emp_mean, linetype = "solid", linewidth = 0.8) +
      labs(
        title = expression(paste("Sampling Dist. of ", hat(theta)[1], " = X" [i] )),
        x = expression(hat(theta)[1]), y = "Count"
      ) +
      theme_minimal()+xlim(0,2)
  })

  output$theta2_stats <- renderText({
    paste0(
      "True Œº = ", round(pop_mean, 4),
      "\nE[Œ∏ÃÇ‚ÇÅ] (theoretical) = ", round(E_theta2, 4),
      "\nSample mean of Œ∏ÃÇ‚ÇÅ = ", round(emp_mean, 4),
      "\nEstimated bias = ", round(emp_bias, 4), "  (should be ~ 0)"
    )
  })
})
```

---

## Example 2: Estimator \( \hat{\theta}_2 = \frac{3X_1 + X_2}{5} \)
- \( E(\hat{\theta}_2) = \frac{4}{5}\mu \) ‚Üí **biased** (downward).
- Bias \( = -\frac{1}{5}\mu \).
- Notice how the sampling distribution is **not centered** on the true mean (dashed line).

```{r ui_theta3, context="render"}
fluidPage(
  numericInput("B_t3", "Number of repetitions (B):", value = 3000, min = 100, step = 100),
  actionButton("go_t3", "Simulate Œ∏‚ÇÇ = (3X‚ÇÅ + X‚ÇÇ)/5", class = "btn-primary"),
  plotOutput("theta3_plot", height = 300),
  verbatimTextOutput("theta3_stats")
)
```

```{r server_theta3, context="server"}
observeEvent(input$go_t3, {
  B <- input$B_t3
  x1 <- rexp(B, rate = EXP_RATE)
  x2 <- rexp(B, rate = EXP_RATE)
  theta3 <- (3 * x1 + x2) / 5

  E_theta3 <- (4/5) * pop_mean
  emp_mean <- mean(theta3)
  emp_bias <- emp_mean - pop_mean

  output$theta3_plot <- renderPlot({
    ggplot(data.frame(theta = theta3), aes(x = theta)) +
      geom_histogram(bins = 80, fill = "goldenrod", color = "white") +
      geom_vline(xintercept = pop_mean, linetype = "dashed", linewidth = 1) +
      geom_vline(xintercept = emp_mean, linetype = "solid", linewidth = 0.8) +
      labs(
        title = expression(paste("Sampling Dist. of ", hat(theta)[2], " = (3X"[1], " + X"[2], ")/5")),
        x = expression(hat(theta)[2]), y = "Count"
      ) +
      theme_minimal()+xlim(0,2)
  })

  output$theta3_stats <- renderText({
    paste0(
      "True Œº = ", round(pop_mean, 4),
      "\nE[Œ∏ÃÇ‚ÇÇ] (theoretical) = ", round(E_theta3, 4), "  (= 4/5 Œº)",
      "\nSample mean of Œ∏ÃÇ‚ÇÇ = ", round(emp_mean, 4),
      "\nEstimated bias = ", round(emp_bias, 4),
      "  (theoretical bias = -Œº/5 = ", round(-pop_mean/5, 4), ")"
    )
  })
})
```

---

## Example 3: Estimator \( \hat{\theta}_3 = \bar{X} \) (sample mean of 50 observations)

- \( E(\hat{\theta}_3) = \mu \) ‚Üí **unbiased**.
- Compare the spread of this distribution to Example 1. The sample mean is much more concentrated ‚Äî it has variance \( \sigma^2/n \) instead of \( \sigma^2 \).

```{r ui_theta4, context="render"}
fluidPage(
  numericInput("B_t4", "Number of repetitions (B):", value = 3000),
  actionButton("go_t4", "Simulate mean of 50 obs", class = "btn-primary"),
  plotOutput("theta4_plot"),
  verbatimTextOutput("theta4_stats")
)
```
```{r server_theta4, context="server"}
observeEvent(input$go_t4, {
  B <- input$B_t4
  theta4 <- replicate(B, mean(rexp(50, rate = EXP_RATE)))
  emp_mean <- mean(theta4)
  emp_bias <- emp_mean - pop_mean
  output$theta4_plot <- renderPlot({
    ggplot(data.frame(theta = theta4), aes(x = theta)) +
      geom_histogram(bins = 80, fill = "skyblue", color = "white") +
      geom_vline(xintercept = pop_mean, linetype = "dashed") +
            geom_vline(xintercept = emp_mean, linetype = "solid") +
      theme_minimal()+xlim(0,2)
  })
  output$theta4_stats <- renderText({
    paste0("True Œº = ", round(pop_mean, 4),
           "\nSample mean = ", round(emp_mean, 4),
           "\nEstimated bias = ", round(emp_bias, 4))
  })
})
```

---

## Normal Approximation Problem ‚Äî DiDi App Example

**Before using the simulator, work through the problem analytically:**

1. What is the distribution of the total calls from Cancun? ( \( S_X = \sum X_i \) where \( X_i \sim \text{Bernoulli}(0.4) \) )
2. What is the distribution of the total calls from Puerto Vallarta?
3. Using normal approximation, what is the distribution of \( S_X + S_Y \)?
4. Calculate \( P(S_X + S_Y > 100) \) using `pnorm()`.

Then use the simulator below to check your answer by setting B to a large number (e.g. 5000).

```{r ui_didi, context="render"}
fluidPage(
  h3("DiDi Calls: Two Cities ‚Üí One Total"),
  fluidRow(
    column(3, sliderInput("n_cancun", "Canc√∫n sample size n‚ÇÅ:", min = 10, max = 500, value = 100, step = 10)),
    column(3, sliderInput("n_pv",    "Puerto Vallarta sample size n‚ÇÇ:", min = 10, max = 500, value = 80,  step = 10)),
    column(3, numericInput("p_cancun", "P(call) Canc√∫n p‚ÇÅ:", value = 0.4, min = 0, max = 1, step = 0.01)),
    column(3, numericInput("p_pv",     "P(call) PV p‚ÇÇ:",     value = 0.6, min = 0, max = 1, step = 0.01))
  ),
  fluidRow(
    column(3, numericInput("threshold_calls", "Threshold T (more than T calls):", value = 100, min = 0, step = 1)),
    column(3, numericInput("B_didi", "Number of samples (B):", value = 1, min = 1, step = 1)),
    column(3, actionButton("sample_didi", "Draw B Samples",  class = "btn-info"))
  ),
  plotOutput("didi_plot_cancun", height = 280),
  plotOutput("didi_plot_pv",     height = 280),
  plotOutput("didi_plot_sum",    height = 280),
  verbatimTextOutput("didi_stats"),
  tags$small(HTML("All x-axes fixed to <b>[0, 120]</b>. Only simulated histograms shown."))
)
```
```{r server_didi, context="server"}
rv_didi <- reactiveValues(samp_x = NULL, samp_y = NULL, samp_s = NULL)

render_all_didi <- function(){
  emp_cancun <- NULL; emp_pv <- NULL; emp_sum <- NULL
  if(!is.null(rv_didi$samp_x)){
    emp_cancun <- data.frame(x = rv_didi$samp_x)
  }
  if(!is.null(rv_didi$samp_y)){
    emp_pv <- data.frame(x = rv_didi$samp_y)
  }
  if(!is.null(rv_didi$samp_s)){
    emp_sum <- data.frame(x = rv_didi$samp_s)
  }

  output$didi_plot_cancun <- renderPlot({
    g <- ggplot(emp_cancun, aes(x = x)) +
      geom_histogram(binwidth = 1, fill = "steelblue", alpha = 0.7, boundary = 0) +
      scale_x_continuous(limits = c(0, 120)) +
      labs(title = "Canc√∫n: Calls", x = "Calls", y = "Frequency") +
      theme_minimal()
    g
  })

  output$didi_plot_pv <- renderPlot({
    g <- ggplot(emp_pv, aes(x = x)) +
      geom_histogram(binwidth = 1, fill = "darkorange", alpha = 0.7, boundary = 0) +
      scale_x_continuous(limits = c(0, 120)) +
      labs(title = "Puerto Vallarta: Calls", x = "Calls", y = "Frequency") +
      theme_minimal()
    g
  })

  output$didi_plot_sum <- renderPlot({
    g <- ggplot(emp_sum, aes(x = x)) +
      geom_histogram(binwidth = 1, fill = "purple", alpha = 0.7, boundary = 0) +
      scale_x_continuous(limits = c(0, 120)) +
      labs(title = "Total Calls: X+Y", x = "Total Calls", y = "Frequency") +
      theme_minimal()
    g
  })

  output$didi_stats <- renderText({
    if(!is.null(rv_didi$samp_s)){
      paste0("B = ", length(rv_didi$samp_s),
             "\nMean total calls = ", mean(rv_didi$samp_s))
    } else {
      "No samples yet."
    }
  })
}

observeEvent(input$sample_didi, {
  B <- input$B_didi
  n1 <- input$n_cancun; p1 <- input$p_cancun
  n2 <- input$n_pv;     p2 <- input$p_pv
  rv_didi$samp_x <- rbinom(B, n1, p1)
  rv_didi$samp_y <- rbinom(B, n2, p2)
  rv_didi$samp_s <- rv_didi$samp_x + rv_didi$samp_y
  render_all_didi()
})
```



---

## Visualizing the Connection: Normal vs Chi-square(1)
```{r ui_norm_chi, context="render"}
fluidPage(
  sliderInput("t_chi", "Threshold t for X = Z¬≤ > t:", min = 0, max = 9, value = 1, step = 0.1),
  actionButton("go_chi", "Update", class = "btn-primary"),
  plotOutput("norm_chi_plot", height = 400),
  verbatimTextOutput("norm_chi_stats")
)
```
```{r server_norm_chi, context="server"}
observeEvent(input$go_chi, {
  tval <- input$t_chi
  zc <- sqrt(tval)

  # Densities for Normal and Chi-square(1)
  zgrid <- seq(-4, 4, length.out = 1000)
  dn <- dnorm(zgrid)

  xmax <- max(8, 3*tval)
  xgrid <- seq(0, xmax, length.out = 1000)
  dchi <- dchisq(xgrid, df = 1)

  # Probabilities (should match)
  p_norm <- 2 * pnorm(-zc)                         # P(|Z| > sqrt(t))
  p_chis <- pchisq(tval, df = 1, lower.tail = FALSE)  # P(X > t)

  # Build tail data frames to avoid filling across the center
  dfN_all   <- data.frame(x = zgrid, y = dn)
  dfN_left  <- subset(dfN_all, x <= -zc)
  dfN_right <- subset(dfN_all, x >=  zc)

  dfC_all   <- data.frame(x = xgrid, y = dchi)
  dfC_tail  <- subset(dfC_all, x > tval)

  output$norm_chi_plot <- renderPlot({
    # Side-by-side without extra packages
    library(grid)

    p1 <- ggplot() +
      geom_line(data = dfN_all, aes(x = x, y = y)) +
      geom_area(data = dfN_left,  aes(x = x, y = y), alpha = 0.6) +
      geom_area(data = dfN_right, aes(x = x, y = y), alpha = 0.6) +
      geom_vline(xintercept = c(-zc, zc), linetype = "dashed") +
      labs(title = "Normal: tails P(|Z| > sqrt(t))", x = "z", y = "density") +
      theme_minimal()

    p2 <- ggplot() +
      geom_line(data = dfC_all, aes(x = x, y = y)) +
      geom_area(data = dfC_tail, aes(x = x, y = y), alpha = 0.6) +
      geom_vline(xintercept = tval, linetype = "dashed") +
      labs(title = expression(chi^2*"(1): P(X > t)"), x = "x", y = "density") +
      theme_minimal()

    grid.newpage()
    pushViewport(viewport(layout = grid.layout(1, 2)))
    print(p1, vp = viewport(layout.pos.row = 1, layout.pos.col = 1))
    print(p2, vp = viewport(layout.pos.row = 1, layout.pos.col = 2))
  })

  output$norm_chi_stats <- renderText({
    paste0(
      "P(|Z| > sqrt(t)) = ", signif(p_norm, 6),
      "\nP(X > t)      = ", signif(p_chis, 6),
      "\nDifference     = ", signif(abs(p_norm - p_chis), 6)
    )
  })
})
```

---

## Confidence interval

```{r ui_ci_distance, context="render"}
fluidPage(
  h3("Distance of Sample Mean from Population Mean"),
  fluidRow(
    column(3, numericInput("mu_dist", HTML("&mu; (Population Mean)"), value = 50, step = 0.1)),
    column(3, numericInput("sigma_dist", HTML("&sigma; (Population SD)"), value = 10, min = 0.0001, step = 0.1)),
    column(3, numericInput("n_dist", HTML("n (Sample Size)"), value = 30, min = 1, step = 1)),
    column(3, sliderInput("conf_level", "Confidence Level", min = 0.5, max = 0.999, value = 0.95, step = 0.005))
  ),
  fluidRow(
    column(3, actionButton("draw_sample_dist", "Draw One Sample", class = "btn-primary"))
  ),
  plotOutput("dist_plot", height = 350),
  verbatimTextOutput("dist_stats")
)
```

```{r server_ci_distance, context="server"}
observeEvent(input$draw_sample_dist, {
  mu <- input$mu_dist; sig <- input$sigma_dist; n <- input$n_dist
  se <- sig / sqrt(n)
  conf <- input$conf_level
  zcrit <- qnorm((1 + conf) / 2)

  xbar <- mean(rnorm(n, mean = mu, sd = sig))
  zval <- (xbar - mu) / se

  output$dist_plot <- renderPlot({
    curve(dnorm(x),
          xlim = c(-3, 3),
          main = "",
          yaxs = "i",
          xlab = "Standard Errors",
          ylab = "",
          lwd = 2,
          axes = FALSE)

    # Axis labels for Œº ¬± z*¬∑SE (use actual zcrit, not hardcoded 1.96)
axis(1,
     at = c(-zcrit, 0, zcrit),
     labels = c(
       expression(mu - z[alpha/2] %*% frac(s, sqrt(n))),
       expression(mu),
       expression(mu + z[alpha/2] %*% frac(s, sqrt(n)))
     ),
     padj = 0.75
)

    # Shade CI around Œº
    transparent_color <- rgb(70, 130, 180, alpha = 50, maxColorValue = 255)
    polygon(x = c(-zcrit, seq(-zcrit, zcrit, 0.01), zcrit),
            y = c(0, dnorm(seq(-zcrit, zcrit, 0.01)), 0),
            col = transparent_color)

    # Œº line
    abline(v = 0, col = "red", lwd = 2)
    # Sample mean line
    abline(v = zval, col = "darkgreen", lwd = 2, lty = 2)

    # Axis labels for xÃÑ ¬± z*¬∑SE (centered on xÃÑ)

axis(3,
     at = c(zval - zcrit, zval, zval + zcrit),
     padj = -0.75,
     labels = c(
  expression(bar(x) - z[alpha/2] %*% frac(s, sqrt(n))),
  expression(bar(x)),
  expression(bar(x) + z[alpha/2] %*% frac(s, sqrt(n)))
)
)
    text(zval, 0.05, bquote(bar(x) == .(round(xbar, 2))), pos = ifelse(zval > 0, 4, 2))
    text(0, 0.2, paste0(round(conf*100, 1), "%"), col = "black", cex = 1.3)
  })

  L <- mu - zcrit*se; U <- mu + zcrit*se
  L_xbar <- xbar - zcrit*se; U_xbar <- xbar + zcrit*se
  output$dist_stats <- renderText({
    paste0(
      "xÃÑ = ", round(xbar, 3),
      ",  Œº = ", mu,
      ",  SE = ", round(se, 3),
      ",  z = ", round(zval, 3),
      "\nInterval around Œº: [", round(L,3), ", ", round(U,3), "]",
      "\nInterval around xÃÑ: [", round(L_xbar,3), ", ", round(U_xbar,3), "]",
      "  at ", round(conf*100,1), "% confidence"
    )
  })
})
```


---

## Finding critical values in normal

Find the critical values for a 99% confidence interval in a normal distribution.

```{r addition, exercise=TRUE}

qnorm(0.995) #quantiles from normal distribution

```


---

## Practice

Product analytics at a ride-hailing company wants to estimate the **average ride fare** in a city this month. You'll take a random sample of rides and build a **90% confidence interval** for the mean fare.

> You'll get a hidden population `orders_pop` (thousands of past rides). Your job is to sample from it and compute a CI. At the end, you can click a button to reveal the true mean \(\mu\).



```{r addition22, exercise=TRUE}
# 0) Set seed to your student ID
# set.seed(YOUR_STUDENT_ID)

# 1) Take a random sample of 100 observations from orders_pop (without replacement)
# sample_orders <- sample(orders_pop, size = _____, replace = _____)

# 2) Calculate the sample mean and standard deviation
# xbar <- _____(sample_orders)
# s    <- _____(sample_orders)

# xbar (you can see these values)
# s

# 3) Find the two-sided critical value for a 90% CI
# z_crit <- qnorm(_____)

# 4) Compute the confidence interval for the mean
# se <- s / sqrt(_____)

# 5) show your CI endpoints
# c(xbar - z_crit * se, xbar + z_crit * se)

```

### üîé Reveal the True Mean (after you try!)
```{r ui_reveal_mean, context="render"}
fluidPage(
  actionButton("reveal_mean", "Reveal true mean Œº", class = "btn-warning"),
  verbatimTextOutput("true_mean_out")
)
```

```{r server_reveal_mean, context="server"}
observeEvent(input$reveal_mean, {
  output$true_mean_out <- renderText({
    paste0("True population mean Œº = ", round(true_mu, 3),
           "  (SD = ", round(true_sd, 3), ")")
  })
})
```

---

## Finding critical values in Student's t

Find critical value for an 80% confidence interval for data with 20 observations (df = 19). How does it differ from the normal critical value?

```{r addition56745, exercise=TRUE}
# For 80% CI: alpha = 0.20, so alpha/2 = 0.10
# We need P(T < t) = 1 - alpha/2 = 0.90

qt(0.90, 19)   # t critical value with 19 df
qnorm(0.90)    # compare with normal critical value

```


---

## Practice with student T

Your company implemented **free shipping** for a random group of customers and wants to know whether it **increased spending**.

**Data (free‚Äëshipping group, n = 10):** `spend_free`


a) **Compute a 90% confidence interval** for the mean spending.

```{r free_ship_ex, exercise=TRUE}
# a) 90% confidence interval for the mean (t-based)
# 1) n, xÃÑ, s


# 2) t critical value for 90% CI (two-sided)


# 3) Standard error and CI


# Print CI
# c(ci_lower, ci_upper)

```

---

## Finding critical values in chi-square

Find critical values for a 90% confidence interval for the variance with 20 observations (df = 19).

```{r addition5674523, exercise=TRUE}
# For 90% CI: alpha = 0.10, so alpha/2 = 0.05
# We need the lower and upper quantiles of chi-squared with df = 19

qchisq(0.05, 19)   # lower critical value: P(X < this) = 0.05
qchisq(0.95, 19)   # upper critical value: P(X < this) = 0.95

```

---

## Practice for confidence interval of variance

```{r sausage_variance_ci, exercise=TRUE}
# Scenario: Sausage production quality control
# We measure the fat content in sausages (in grams) and want a 99% CI for the variance.
# Data: sample size n = 12, sample variance s2 = 20 (grams^2)
# Assumption: ?


##save statistics you need (n,s2 etc)


# Find Chi-square critical values
lower_crit <- 
upper_crit <- 

# Compute 99% confidence interval for variance
lower_ci <- 
upper_ci <- 

lower_ci
upper_ci
```

---

## Testing intuition

Suppose we want to test H‚ÇÄ: Œº = 100. Let's see what samples look like when the null is true vs. when it's false.

Take a sample of 36 when the true mean **is** 100 (null is true):

```{r t1, exercise=TRUE}
set.seed(3)
x_100 <- rnorm(n = 36, mean = 100, sd = 20) # sample from N(100, 20)
mean(x_100)

```
Take a sample of 36 when the true mean is 108 (null is false):

```{r t2, exercise=TRUE}
set.seed(3)
x_108 <- rnorm(n = 36, mean = 108, sd = 20) # sample from N(108, 20)
mean(x_108)

```



---

## Probability of incorrectly rejecting the null (Type 1 error)

Suppose H‚ÇÄ: Œº = 100 is **true**. We'll generate 1000 samples from N(100, 20) and see how often we'd incorrectly reject.

```{r t123, exercise=TRUE}

# Generate 1000 sample means when the null is TRUE (Œº = 100)
means_100 <- replicate(1000, mean(rnorm(36, mean = 100, sd = 20)))
head(means_100)

hist(means_100, main="Sampling Distribution of Mean (Œº=100, null is true)", xlab="Sample mean")

# Standardize them under H0: Œº‚ÇÄ = 100
# standardized_means <- (means_100 - 100) / (20 / sqrt(36))
# head(standardized_means)

# How many exceed the critical value (one-sided, Œ± = 0.05)?
# sum(standardized_means > 1.645)
```

---

## Critical values

Finding critical value for a given level of type 1 error

```{r error_prob, exercise=TRUE}
qnorm(0.95) #quantiles from normal distribution

```

---

## Probability of incorrectly failing to reject (Type 2 error)

Now suppose the **true** mean is Œº = 110, but we are testing H‚ÇÄ: Œº = 100. How often do we **fail** to reject?

```{r t1234, exercise=TRUE}

# Generate 1000 sample means when the true mean is 110 (null is FALSE)
means_110 <- replicate(1000, mean(rnorm(36, mean = 110, sd = 20)))
head(means_110)

hist(means_110, main="Sampling Distribution of Mean (true Œº=110)", xlab="Sample mean")

# Standardize under H0: Œº‚ÇÄ = 100 (we don't know the true mean in practice!)
# standardized_means <- (means_110 - 100) / (20 / sqrt(36))
# head(standardized_means)

# How many FAIL to exceed the critical value? (Type 2 error)
# sum(standardized_means < 1.645)
```

---

## Type 2 error

```{r t12345, exercise=TRUE}

pnorm(-1)
```

---

## Power

Power = 1 - P(Type 2 error) = probability of correctly rejecting a false null.

```{r t1233234, exercise=TRUE}

# Generate 1000 sample means when the true mean is 110 (null is FALSE)
means_110 <- replicate(1000, mean(rnorm(36, mean = 110, sd = 20)))
head(means_110)

hist(means_110, main="Sampling Distribution of Mean (true Œº=110)", xlab="Sample mean")

# Standardize under H0: Œº‚ÇÄ = 100
# standardized_means <- (means_110 - 100) / (20 / sqrt(36))
# head(standardized_means)

# Power = proportion that correctly reject (exceed critical value)
# sum(standardized_means > 1.645) / length(standardized_means)
```

---


## Power exercise:

Airbnb wants to test whether offering professional photographic services to hosts increases weekly revenue per listing.

You need to design the test which will have a good power and will be cheap to make (low n). 

- Design. Run an A/B experiment with equal-sized groups:
  - Control (A): no photos (baseline) $\mu_0=2000$.
  - Treatment (B): professional photos. You suspect it increases revenue to $\mu_a=2200$.

- Assume that the standard deviation of weekly revenue is $\sigma=600$.
- Suppose you take a sample of 100 listings per group.
- And you want the type 1 error probability to be 1%.


#### Step 0 ‚Äî State the hypotheses 


#### Step 1 - Find the critical value

```{r ex_power_1, exercise=TRUE}

```


#### Step 2 ‚Äî Write down the formula for the power

```{r ex_power_2, exercise=TRUE}
n=100
sigma=600
u0=2000
ua=2200
crit_value=qnorm(0.99)


```


Providing photographic services is costly, what is the minimum $n$ so you still get power of 80%?

#### Step 3 ‚Äî Find relevant n

```{r ex_power_3, exercise=TRUE}


```


What if we flip the hypothesis? - We want to check whether it decreases revenue?

```{r ex_power_4, exercise=TRUE}
n=100
sigma=600
u0=2000
ua=2200
crit_value=qnorm(0.99)


```

---

## One-Sample t-test: Tweet Engagement

Suppose the marketing team at **Twitter/X** wants to test whether  
their new campaign is generating at least **200 likes per tweet** on average.  

We collect a random sample of 50 tweets from the campaign and measure their number of likes. Suppose 5% significance level. 

 
```{r setup-tweets, include=FALSE}
set.seed(124)

# Generate synthetic tweet likes around mean ~210 with some variation
tweets <- data.frame(
  likes = rnbinom(50, size = 20, mu = 190)  # 50 tweets
)
```

Step 1. Set up the hypothesis


Step 2. Calculate the test statistic

```{r ex_tw1, exercise=TRUE , exercise.setup="setup-tweets"}

Mean=___ # mean of tweets
S=___ # standard deviation of tweets
SE=_____ #standard error of the estimator

Test_stat=(M-200)/SE



```


Step 3. Find the critical value

```{r ex_tw2, exercise=TRUE , exercise.setup="setup-tweets"}



```

Step 4. Conclude



Would you reject at 1%?
What is the smallest alpha at which you would still reject?

```{r ex_tw3, exercise=TRUE , exercise.setup="setup-tweets"}


```


---

## P values


We want to test whether a coin is fair:

- **H‚ÇÄ:** œÄ = 0.50 (the coin is fair)  
- **H‚ÇÅ:** œÄ ‚â† 0.50 (the coin is biased)  

Suppose we toss a coin 100 times and observe **58 heads**.  What is the p-value?

```{r ex_coin_1, exercise=TRUE}

# Proportion of heads observed


# What's the variance if the null is true?


# What's the Standard error of the estimator


# Test statistic


# p-value


```



---

## Two Sample Difference, Airbnb Example

Find the p-value for the hypothesis that the mean prices are equal.

```{r ex_0131, exercise=TRUE}

C=1245
D=869
SDC=962
SDD=693
nC=100
nD=100





```

Do we reject at 10%, 5%, 1%?

---

## AB Testing Randomization

Before this exercise - load the data on airbnb Listings

Step 1: Let's first take a random sample of 2000 listings for our experiment
```{r ex_AB_1, exercise=TRUE}
# Load your listing data ‚Äî update the path to match your local directory
load("../../Intro_to_r/listings.Rda")

listings$bed_num=as.numeric(listings$beds) ##transform number of beds to numeric and 
listings=listings[!is.na(listings$bed_num),] ### keep only those with a valid number of beds
exp_listings <- listings[sample(nrow(listings), size = 2000, replace = FALSE), ]


```

Step 2: Let's randomize them into treatment and control group
  - With 50% probability you are in the treatment, otherwise in control
```{r ex_AB_2, exercise=TRUE, exercise.setup="ex_AB_1"}

exp_listings$group <- ifelse(rbinom(nrow(exp_listings), 1, 0.5) == 1, "Treatment", "Control") # Draw a Bernoulli variable (binomial with n=1) for everyone. If you got 1, you are treated; if 0, control

table(exp_listings$group)

```


Step 3: Let's check if number of beds and neighborhoods are more or else equally distributed among the two groups
```{r ex_AB_3, exercise=TRUE, exercise.setup="ex_AB_2"}
##transform to numeric
A=exp_listings$bed_num[exp_listings$group=="Treatment"]
B=exp_listings$bed_num[exp_listings$group=="Control"]

(mean(A)-___)/sqrt(var(A)/___+var(B)/___) #t statistic for difference in means


#how would you check if the distribution across neighborhoods is equal?
table(exp_listings$neighbourhood_cleansed,exp_listings$group) 

```

Now we can organize photography for the treatment group and run the experiment! After a month we run a test to see if they have higher number of bookings. This would be a causal difference due to photography, because everything else is the same across the two groups!

---

## Paired Data test for means

A psychologist thinks that age influences IQ. They take a random sample of 100 people of age 40. For each person we know their IQ at age 16 and now. On average, in this sample, IQ at young age was 8 points higher than at age 40. Standard deviation of that difference was 7 points. Using  Œ±=0.01 test the hypothesis that IQ decreases with age.
 

```{r ex_0131342342, exercise=TRUE}
n=100
Diff=8
SD=7
alpha=0.01


```





---

## Paired Data Test for Correlation

Suppose you have a random sample of 27 units (from a bivariate normal). X measures client's age and Y measures their spending. You calculated the correlation coefficient of 0.45. Can you reject null of 
œÅ=0 in favor of alternative  œÅ‚â†0 at 5% significance level?

```{r ex_01313423443432, exercise=TRUE}

```

---